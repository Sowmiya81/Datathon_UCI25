{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ac93706-0b45-4fca-8239-8bb4e7d964ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecf80836-c127-450b-aee2-0a07343a47b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>prompt_valuable</th>\n",
       "      <th>response_a_cleaned</th>\n",
       "      <th>response_b_cleaned</th>\n",
       "      <th>jaccard_sim_resp_a</th>\n",
       "      <th>jaccard_sim_resp_b</th>\n",
       "      <th>bow_sim_resp_A</th>\n",
       "      <th>bow_sim_resp_B</th>\n",
       "      <th>num_words_response_a</th>\n",
       "      <th>num_words_response_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>Is it morally right to try to have a certain p...</td>\n",
       "      <td>The question of whether it is morally right to...</td>\n",
       "      <td>As an AI, I dont have personal beliefs or opin...</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.087912</td>\n",
       "      <td>0.479368</td>\n",
       "      <td>0.355151</td>\n",
       "      <td>415</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the difference between marriage licens...</td>\n",
       "      <td>A marriage license is a legal document that al...</td>\n",
       "      <td>A marriage license and a marriage certificate ...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.462613</td>\n",
       "      <td>0.602066</td>\n",
       "      <td>121</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>explain function calling. how would you call a...</td>\n",
       "      <td>Function calling is the process of invoking or...</td>\n",
       "      <td>Function calling is the process of invoking a ...</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.453495</td>\n",
       "      <td>0.302969</td>\n",
       "      <td>141</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>How can I create a test set for a very rare ca...</td>\n",
       "      <td>Creating a test set for a very rare category c...</td>\n",
       "      <td>When building a classifier for a very rare cat...</td>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.082645</td>\n",
       "      <td>0.556717</td>\n",
       "      <td>0.396433</td>\n",
       "      <td>547</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the best way to travel from Tel-Aviv t...</td>\n",
       "      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n",
       "      <td>The best way to travel from Tel-Aviv to Jerusa...</td>\n",
       "      <td>0.089431</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.488893</td>\n",
       "      <td>0.581541</td>\n",
       "      <td>231</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_a              model_b  \\\n",
       "0  gpt-4-1106-preview           gpt-4-0613   \n",
       "1           koala-13b           gpt-4-0613   \n",
       "2  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4           koala-13b   gpt-3.5-turbo-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  [\"Is it morally right to try to have a certain...   \n",
       "1  [\"What is the difference between marriage lice...   \n",
       "2  [\"explain function calling. how would you call...   \n",
       "3  [\"How can I create a test set for a very rare ...   \n",
       "4  [\"What is the best way to travel from Tel-Aviv...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  [\"The question of whether it is morally right ...   \n",
       "1  [\"A marriage license is a legal document that ...   \n",
       "2  [\"Function calling is the process of invoking ...   \n",
       "3  [\"Creating a test set for a very rare category...   \n",
       "4  [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "\n",
       "                                          response_b  winner  \\\n",
       "0  [\"As an AI, I don't have personal beliefs or o...       1   \n",
       "1  [\"A marriage license and a marriage certificat...       2   \n",
       "2  [\"Function calling is the process of invoking ...       0   \n",
       "3  [\"When building a classifier for a very rare c...       1   \n",
       "4  [\"The best way to travel from Tel-Aviv to Jeru...       2   \n",
       "\n",
       "                                     prompt_valuable  \\\n",
       "0  Is it morally right to try to have a certain p...   \n",
       "1  What is the difference between marriage licens...   \n",
       "2  explain function calling. how would you call a...   \n",
       "3  How can I create a test set for a very rare ca...   \n",
       "4  What is the best way to travel from Tel-Aviv t...   \n",
       "\n",
       "                                  response_a_cleaned  \\\n",
       "0  The question of whether it is morally right to...   \n",
       "1  A marriage license is a legal document that al...   \n",
       "2  Function calling is the process of invoking or...   \n",
       "3  Creating a test set for a very rare category c...   \n",
       "4  The best way to travel from Tel Aviv to Jerusa...   \n",
       "\n",
       "                                  response_b_cleaned  jaccard_sim_resp_a  \\\n",
       "0  As an AI, I dont have personal beliefs or opin...            0.058824   \n",
       "1  A marriage license and a marriage certificate ...            0.090909   \n",
       "2  Function calling is the process of invoking a ...            0.059524   \n",
       "3  When building a classifier for a very rare cat...            0.064327   \n",
       "4  The best way to travel from Tel-Aviv to Jerusa...            0.089431   \n",
       "\n",
       "   jaccard_sim_resp_b  bow_sim_resp_A  bow_sim_resp_B  num_words_response_a  \\\n",
       "0            0.087912        0.479368        0.355151                   415   \n",
       "1            0.053571        0.462613        0.602066                   121   \n",
       "2            0.031746        0.453495        0.302969                   141   \n",
       "3            0.082645        0.556717        0.396433                   547   \n",
       "4            0.153846        0.488893        0.581541                   231   \n",
       "\n",
       "   num_words_response_b  \n",
       "0                   117  \n",
       "1                   204  \n",
       "2                   280  \n",
       "3                   271  \n",
       "4                   124  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('arun.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24657b26-3a10-4c50-a0dc-ac6250945bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cos = pd.read_csv('cosine.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb5c16eb-4d74-4a29-9fb4-63b4e433970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = df_cos.loc[:,'similarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9deea0da-463a-4f4d-ab5a-59d5ef1be358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>prompt_valuable</th>\n",
       "      <th>response_a_cleaned</th>\n",
       "      <th>response_b_cleaned</th>\n",
       "      <th>jaccard_sim_resp_a</th>\n",
       "      <th>jaccard_sim_resp_b</th>\n",
       "      <th>bow_sim_resp_A</th>\n",
       "      <th>bow_sim_resp_B</th>\n",
       "      <th>num_words_response_a</th>\n",
       "      <th>num_words_response_b</th>\n",
       "      <th>cosine_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>Is it morally right to try to have a certain p...</td>\n",
       "      <td>The question of whether it is morally right to...</td>\n",
       "      <td>As an AI, I dont have personal beliefs or opin...</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.087912</td>\n",
       "      <td>0.479368</td>\n",
       "      <td>0.355151</td>\n",
       "      <td>415</td>\n",
       "      <td>117</td>\n",
       "      <td>0.496171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the difference between marriage licens...</td>\n",
       "      <td>A marriage license is a legal document that al...</td>\n",
       "      <td>A marriage license and a marriage certificate ...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.462613</td>\n",
       "      <td>0.602066</td>\n",
       "      <td>121</td>\n",
       "      <td>204</td>\n",
       "      <td>0.638639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>explain function calling. how would you call a...</td>\n",
       "      <td>Function calling is the process of invoking or...</td>\n",
       "      <td>Function calling is the process of invoking a ...</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.453495</td>\n",
       "      <td>0.302969</td>\n",
       "      <td>141</td>\n",
       "      <td>280</td>\n",
       "      <td>0.614142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>How can I create a test set for a very rare ca...</td>\n",
       "      <td>Creating a test set for a very rare category c...</td>\n",
       "      <td>When building a classifier for a very rare cat...</td>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.082645</td>\n",
       "      <td>0.556717</td>\n",
       "      <td>0.396433</td>\n",
       "      <td>547</td>\n",
       "      <td>271</td>\n",
       "      <td>0.731076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the best way to travel from Tel-Aviv t...</td>\n",
       "      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n",
       "      <td>The best way to travel from Tel-Aviv to Jerusa...</td>\n",
       "      <td>0.089431</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.488893</td>\n",
       "      <td>0.581541</td>\n",
       "      <td>231</td>\n",
       "      <td>124</td>\n",
       "      <td>0.636448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57472</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>[\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...</td>\n",
       "      <td>[\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...</td>\n",
       "      <td>[\"Here is how that mnemonic represents the dig...</td>\n",
       "      <td>1</td>\n",
       "      <td>A simple mnemonic for How I wish I could enume...</td>\n",
       "      <td>Sure, lets break it down 1. How has 3 letters....</td>\n",
       "      <td>Here is how that mnemonic represents the digit...</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.232147</td>\n",
       "      <td>0.459660</td>\n",
       "      <td>69</td>\n",
       "      <td>81</td>\n",
       "      <td>0.301794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57473</th>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>[\"In python, implement a naive Bayes with gaus...</td>\n",
       "      <td>[\"Here is an implementation of a naive Bayes c...</td>\n",
       "      <td>[\"Sure! Here's an implementation of a naive Ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>In python, implement a naive Bayes with gaussi...</td>\n",
       "      <td>Here is an implementation of a naive Bayes cla...</td>\n",
       "      <td>Sure Heres an implementation of a naive Bayes ...</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.353903</td>\n",
       "      <td>0.511576</td>\n",
       "      <td>145</td>\n",
       "      <td>156</td>\n",
       "      <td>0.670794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57474</th>\n",
       "      <td>claude-1</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>[\"is it unethical to work on building weapons?...</td>\n",
       "      <td>[\"Working on weapons technology raises some et...</td>\n",
       "      <td>[\"It depends on the context. Weapons can be us...</td>\n",
       "      <td>1</td>\n",
       "      <td>is it unethical to work on building weapons</td>\n",
       "      <td>Working on weapons technology raises some ethi...</td>\n",
       "      <td>It depends on the context. Weapons can be used...</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.301329</td>\n",
       "      <td>0.426067</td>\n",
       "      <td>319</td>\n",
       "      <td>85</td>\n",
       "      <td>0.371905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57475</th>\n",
       "      <td>palm-2</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>[\"If a bait contains 0,0025% bromadiolon then ...</td>\n",
       "      <td>[\"Bromadiolone is a rodenticide which is most ...</td>\n",
       "      <td>[\"As an AI language model, I do not promote or...</td>\n",
       "      <td>2</td>\n",
       "      <td>If a bait contains 0,0025 bromadiolon then how...</td>\n",
       "      <td>Bromadiolone is a rodenticide which is most of...</td>\n",
       "      <td>As an AI language model, I do not promote or c...</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.136998</td>\n",
       "      <td>0.272707</td>\n",
       "      <td>75</td>\n",
       "      <td>162</td>\n",
       "      <td>0.542418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57476</th>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[\"three kids eat three apples in three days, h...</td>\n",
       "      <td>[\"27 apples\"]</td>\n",
       "      <td>[\"If three kids eat three apples in three days...</td>\n",
       "      <td>1</td>\n",
       "      <td>three kids eat three apples in three days, how...</td>\n",
       "      <td>27 apples</td>\n",
       "      <td>If three kids eat three apples in three days, ...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.242536</td>\n",
       "      <td>0.762962</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>0.657108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57240 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model_a              model_b  \\\n",
       "0      gpt-4-1106-preview           gpt-4-0613   \n",
       "1               koala-13b           gpt-4-0613   \n",
       "2      gpt-3.5-turbo-0613       mistral-medium   \n",
       "3        llama-2-13b-chat  mistral-7b-instruct   \n",
       "4               koala-13b   gpt-3.5-turbo-0314   \n",
       "...                   ...                  ...   \n",
       "57472          gpt-4-0613             claude-1   \n",
       "57473          claude-2.0     llama-2-13b-chat   \n",
       "57474            claude-1           alpaca-13b   \n",
       "57475              palm-2       tulu-2-dpo-70b   \n",
       "57476  gemini-pro-dev-api   gpt-4-1106-preview   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      [\"Is it morally right to try to have a certain...   \n",
       "1      [\"What is the difference between marriage lice...   \n",
       "2      [\"explain function calling. how would you call...   \n",
       "3      [\"How can I create a test set for a very rare ...   \n",
       "4      [\"What is the best way to travel from Tel-Aviv...   \n",
       "...                                                  ...   \n",
       "57472  [\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...   \n",
       "57473  [\"In python, implement a naive Bayes with gaus...   \n",
       "57474  [\"is it unethical to work on building weapons?...   \n",
       "57475  [\"If a bait contains 0,0025% bromadiolon then ...   \n",
       "57476  [\"three kids eat three apples in three days, h...   \n",
       "\n",
       "                                              response_a  \\\n",
       "0      [\"The question of whether it is morally right ...   \n",
       "1      [\"A marriage license is a legal document that ...   \n",
       "2      [\"Function calling is the process of invoking ...   \n",
       "3      [\"Creating a test set for a very rare category...   \n",
       "4      [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "...                                                  ...   \n",
       "57472  [\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...   \n",
       "57473  [\"Here is an implementation of a naive Bayes c...   \n",
       "57474  [\"Working on weapons technology raises some et...   \n",
       "57475  [\"Bromadiolone is a rodenticide which is most ...   \n",
       "57476                                      [\"27 apples\"]   \n",
       "\n",
       "                                              response_b  winner  \\\n",
       "0      [\"As an AI, I don't have personal beliefs or o...       1   \n",
       "1      [\"A marriage license and a marriage certificat...       2   \n",
       "2      [\"Function calling is the process of invoking ...       0   \n",
       "3      [\"When building a classifier for a very rare c...       1   \n",
       "4      [\"The best way to travel from Tel-Aviv to Jeru...       2   \n",
       "...                                                  ...     ...   \n",
       "57472  [\"Here is how that mnemonic represents the dig...       1   \n",
       "57473  [\"Sure! Here's an implementation of a naive Ba...       1   \n",
       "57474  [\"It depends on the context. Weapons can be us...       1   \n",
       "57475  [\"As an AI language model, I do not promote or...       2   \n",
       "57476  [\"If three kids eat three apples in three days...       1   \n",
       "\n",
       "                                         prompt_valuable  \\\n",
       "0      Is it morally right to try to have a certain p...   \n",
       "1      What is the difference between marriage licens...   \n",
       "2      explain function calling. how would you call a...   \n",
       "3      How can I create a test set for a very rare ca...   \n",
       "4      What is the best way to travel from Tel-Aviv t...   \n",
       "...                                                  ...   \n",
       "57472  A simple mnemonic for How I wish I could enume...   \n",
       "57473  In python, implement a naive Bayes with gaussi...   \n",
       "57474        is it unethical to work on building weapons   \n",
       "57475  If a bait contains 0,0025 bromadiolon then how...   \n",
       "57476  three kids eat three apples in three days, how...   \n",
       "\n",
       "                                      response_a_cleaned  \\\n",
       "0      The question of whether it is morally right to...   \n",
       "1      A marriage license is a legal document that al...   \n",
       "2      Function calling is the process of invoking or...   \n",
       "3      Creating a test set for a very rare category c...   \n",
       "4      The best way to travel from Tel Aviv to Jerusa...   \n",
       "...                                                  ...   \n",
       "57472  Sure, lets break it down 1. How has 3 letters....   \n",
       "57473  Here is an implementation of a naive Bayes cla...   \n",
       "57474  Working on weapons technology raises some ethi...   \n",
       "57475  Bromadiolone is a rodenticide which is most of...   \n",
       "57476                                          27 apples   \n",
       "\n",
       "                                      response_b_cleaned  jaccard_sim_resp_a  \\\n",
       "0      As an AI, I dont have personal beliefs or opin...            0.058824   \n",
       "1      A marriage license and a marriage certificate ...            0.090909   \n",
       "2      Function calling is the process of invoking a ...            0.059524   \n",
       "3      When building a classifier for a very rare cat...            0.064327   \n",
       "4      The best way to travel from Tel-Aviv to Jerusa...            0.089431   \n",
       "...                                                  ...                 ...   \n",
       "57472  Here is how that mnemonic represents the digit...            0.190476   \n",
       "57473  Sure Heres an implementation of a naive Bayes ...            0.152000   \n",
       "57474  It depends on the context. Weapons can be used...            0.033520   \n",
       "57475  As an AI language model, I do not promote or c...            0.060606   \n",
       "57476  If three kids eat three apples in three days, ...            0.083333   \n",
       "\n",
       "       jaccard_sim_resp_b  bow_sim_resp_A  bow_sim_resp_B  \\\n",
       "0                0.087912        0.479368        0.355151   \n",
       "1                0.053571        0.462613        0.602066   \n",
       "2                0.031746        0.453495        0.302969   \n",
       "3                0.082645        0.556717        0.396433   \n",
       "4                0.153846        0.488893        0.581541   \n",
       "...                   ...             ...             ...   \n",
       "57472            0.271186        0.232147        0.459660   \n",
       "57473            0.256410        0.353903        0.511576   \n",
       "57474            0.111111        0.301329        0.426067   \n",
       "57475            0.064516        0.136998        0.272707   \n",
       "57476            0.256410        0.242536        0.762962   \n",
       "\n",
       "       num_words_response_a  num_words_response_b  cosine_sim  \n",
       "0                       415                   117    0.496171  \n",
       "1                       121                   204    0.638639  \n",
       "2                       141                   280    0.614142  \n",
       "3                       547                   271    0.731076  \n",
       "4                       231                   124    0.636448  \n",
       "...                     ...                   ...         ...  \n",
       "57472                    69                    81    0.301794  \n",
       "57473                   145                   156    0.670794  \n",
       "57474                   319                    85    0.371905  \n",
       "57475                    75                   162    0.542418  \n",
       "57476                     2                   103    0.657108  \n",
       "\n",
       "[57240 rows x 16 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cosine_sim'] = similarity\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e734c893-2ab4-44fa-847f-c1b4f789fcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>prompt_valuable</th>\n",
       "      <th>response_a_cleaned</th>\n",
       "      <th>response_b_cleaned</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>...</th>\n",
       "      <th>resp_b_avg_sent_len</th>\n",
       "      <th>verbosity_diff</th>\n",
       "      <th>a_to_prompt_valuable_ratio</th>\n",
       "      <th>b_to_prompt_valuable_ratio</th>\n",
       "      <th>self_ref_diff</th>\n",
       "      <th>self_promo_diff</th>\n",
       "      <th>fp_ratio_diff</th>\n",
       "      <th>prompt_valuable_category</th>\n",
       "      <th>sentiment_score_response_a</th>\n",
       "      <th>sentiment_score_response_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>Is it morally right to try to have a certain p...</td>\n",
       "      <td>The question of whether it is morally right to...</td>\n",
       "      <td>As an AI, I dont have personal beliefs or opin...</td>\n",
       "      <td>['is', 'it', 'morally', 'right', 'to', 'try', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>19.500</td>\n",
       "      <td>298.0</td>\n",
       "      <td>24.412</td>\n",
       "      <td>6.882</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>general</td>\n",
       "      <td>0.9883</td>\n",
       "      <td>0.7951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the difference between marriage licens...</td>\n",
       "      <td>A marriage license is a legal document that al...</td>\n",
       "      <td>A marriage license and a marriage certificate ...</td>\n",
       "      <td>['what', 'is', 'the', 'difference', 'between',...</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>11.000</td>\n",
       "      <td>18.545</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.9231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>explain function calling. how would you call a...</td>\n",
       "      <td>Function calling is the process of invoking or...</td>\n",
       "      <td>Function calling is the process of invoking a ...</td>\n",
       "      <td>['explain', 'function', 'calling', 'how', 'wou...</td>\n",
       "      <td>...</td>\n",
       "      <td>18.667</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>14.100</td>\n",
       "      <td>28.000</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>computation</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>-0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>How can I create a test set for a very rare ca...</td>\n",
       "      <td>Creating a test set for a very rare category c...</td>\n",
       "      <td>When building a classifier for a very rare cat...</td>\n",
       "      <td>['how', 'can', 'create', 'test', 'set', 'for',...</td>\n",
       "      <td>...</td>\n",
       "      <td>15.056</td>\n",
       "      <td>276.0</td>\n",
       "      <td>28.789</td>\n",
       "      <td>14.263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the best way to travel from Tel-Aviv t...</td>\n",
       "      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n",
       "      <td>The best way to travel from Tel-Aviv to Jerusa...</td>\n",
       "      <td>['what', 'is', 'the', 'best', 'way', 'to', 'tr...</td>\n",
       "      <td>...</td>\n",
       "      <td>15.500</td>\n",
       "      <td>107.0</td>\n",
       "      <td>15.400</td>\n",
       "      <td>8.267</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>0.8519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57472</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>[\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...</td>\n",
       "      <td>[\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...</td>\n",
       "      <td>[\"Here is how that mnemonic represents the dig...</td>\n",
       "      <td>1</td>\n",
       "      <td>A simple mnemonic for How I wish I could enume...</td>\n",
       "      <td>Sure, lets break it down 1. How has 3 letters....</td>\n",
       "      <td>Here is how that mnemonic represents the digit...</td>\n",
       "      <td>['simple', 'mnemonic', 'for', 'how', 'wish', '...</td>\n",
       "      <td>...</td>\n",
       "      <td>8.100</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>2.379</td>\n",
       "      <td>2.793</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>0.8689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57473</th>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>[\"In python, implement a naive Bayes with gaus...</td>\n",
       "      <td>[\"Here is an implementation of a naive Bayes c...</td>\n",
       "      <td>[\"Sure! Here's an implementation of a naive Ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>In python, implement a naive Bayes with gaussi...</td>\n",
       "      <td>Here is an implementation of a naive Bayes cla...</td>\n",
       "      <td>Sure Heres an implementation of a naive Bayes ...</td>\n",
       "      <td>['in', 'python', 'implement', 'naive', 'bayes'...</td>\n",
       "      <td>...</td>\n",
       "      <td>4.105</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>3.537</td>\n",
       "      <td>3.805</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>computation</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>-0.7506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57474</th>\n",
       "      <td>claude-1</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>[\"is it unethical to work on building weapons?...</td>\n",
       "      <td>[\"Working on weapons technology raises some et...</td>\n",
       "      <td>[\"It depends on the context. Weapons can be us...</td>\n",
       "      <td>1</td>\n",
       "      <td>is it unethical to work on building weapons</td>\n",
       "      <td>Working on weapons technology raises some ethi...</td>\n",
       "      <td>It depends on the context. Weapons can be used...</td>\n",
       "      <td>['is', 'it', 'unethical', 'to', 'work', 'on', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000</td>\n",
       "      <td>234.0</td>\n",
       "      <td>35.444</td>\n",
       "      <td>9.444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>general</td>\n",
       "      <td>-0.9881</td>\n",
       "      <td>-0.7762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57475</th>\n",
       "      <td>palm-2</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>[\"If a bait contains 0,0025% bromadiolon then ...</td>\n",
       "      <td>[\"Bromadiolone is a rodenticide which is most ...</td>\n",
       "      <td>[\"As an AI language model, I do not promote or...</td>\n",
       "      <td>2</td>\n",
       "      <td>If a bait contains 0,0025 bromadiolon then how...</td>\n",
       "      <td>Bromadiolone is a rodenticide which is most of...</td>\n",
       "      <td>As an AI language model, I do not promote or c...</td>\n",
       "      <td>['if', 'bait', 'contains', 'bromadiolon', 'the...</td>\n",
       "      <td>...</td>\n",
       "      <td>16.200</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>3.571</td>\n",
       "      <td>7.714</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>qa</td>\n",
       "      <td>-0.7430</td>\n",
       "      <td>-0.8774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57476</th>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[\"three kids eat three apples in three days, h...</td>\n",
       "      <td>[\"27 apples\"]</td>\n",
       "      <td>[\"If three kids eat three apples in three days...</td>\n",
       "      <td>1</td>\n",
       "      <td>three kids eat three apples in three days, how...</td>\n",
       "      <td>27 apples</td>\n",
       "      <td>If three kids eat three apples in three days, ...</td>\n",
       "      <td>['three', 'kids', 'eat', 'three', 'apples', 'i...</td>\n",
       "      <td>...</td>\n",
       "      <td>25.750</td>\n",
       "      <td>-101.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>5.421</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57240 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model_a              model_b  \\\n",
       "0      gpt-4-1106-preview           gpt-4-0613   \n",
       "1               koala-13b           gpt-4-0613   \n",
       "2      gpt-3.5-turbo-0613       mistral-medium   \n",
       "3        llama-2-13b-chat  mistral-7b-instruct   \n",
       "4               koala-13b   gpt-3.5-turbo-0314   \n",
       "...                   ...                  ...   \n",
       "57472          gpt-4-0613             claude-1   \n",
       "57473          claude-2.0     llama-2-13b-chat   \n",
       "57474            claude-1           alpaca-13b   \n",
       "57475              palm-2       tulu-2-dpo-70b   \n",
       "57476  gemini-pro-dev-api   gpt-4-1106-preview   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      [\"Is it morally right to try to have a certain...   \n",
       "1      [\"What is the difference between marriage lice...   \n",
       "2      [\"explain function calling. how would you call...   \n",
       "3      [\"How can I create a test set for a very rare ...   \n",
       "4      [\"What is the best way to travel from Tel-Aviv...   \n",
       "...                                                  ...   \n",
       "57472  [\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...   \n",
       "57473  [\"In python, implement a naive Bayes with gaus...   \n",
       "57474  [\"is it unethical to work on building weapons?...   \n",
       "57475  [\"If a bait contains 0,0025% bromadiolon then ...   \n",
       "57476  [\"three kids eat three apples in three days, h...   \n",
       "\n",
       "                                              response_a  \\\n",
       "0      [\"The question of whether it is morally right ...   \n",
       "1      [\"A marriage license is a legal document that ...   \n",
       "2      [\"Function calling is the process of invoking ...   \n",
       "3      [\"Creating a test set for a very rare category...   \n",
       "4      [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "...                                                  ...   \n",
       "57472  [\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...   \n",
       "57473  [\"Here is an implementation of a naive Bayes c...   \n",
       "57474  [\"Working on weapons technology raises some et...   \n",
       "57475  [\"Bromadiolone is a rodenticide which is most ...   \n",
       "57476                                      [\"27 apples\"]   \n",
       "\n",
       "                                              response_b  winner  \\\n",
       "0      [\"As an AI, I don't have personal beliefs or o...       1   \n",
       "1      [\"A marriage license and a marriage certificat...       2   \n",
       "2      [\"Function calling is the process of invoking ...       0   \n",
       "3      [\"When building a classifier for a very rare c...       1   \n",
       "4      [\"The best way to travel from Tel-Aviv to Jeru...       2   \n",
       "...                                                  ...     ...   \n",
       "57472  [\"Here is how that mnemonic represents the dig...       1   \n",
       "57473  [\"Sure! Here's an implementation of a naive Ba...       1   \n",
       "57474  [\"It depends on the context. Weapons can be us...       1   \n",
       "57475  [\"As an AI language model, I do not promote or...       2   \n",
       "57476  [\"If three kids eat three apples in three days...       1   \n",
       "\n",
       "                                         prompt_valuable  \\\n",
       "0      Is it morally right to try to have a certain p...   \n",
       "1      What is the difference between marriage licens...   \n",
       "2      explain function calling. how would you call a...   \n",
       "3      How can I create a test set for a very rare ca...   \n",
       "4      What is the best way to travel from Tel-Aviv t...   \n",
       "...                                                  ...   \n",
       "57472  A simple mnemonic for How I wish I could enume...   \n",
       "57473  In python, implement a naive Bayes with gaussi...   \n",
       "57474        is it unethical to work on building weapons   \n",
       "57475  If a bait contains 0,0025 bromadiolon then how...   \n",
       "57476  three kids eat three apples in three days, how...   \n",
       "\n",
       "                                      response_a_cleaned  \\\n",
       "0      The question of whether it is morally right to...   \n",
       "1      A marriage license is a legal document that al...   \n",
       "2      Function calling is the process of invoking or...   \n",
       "3      Creating a test set for a very rare category c...   \n",
       "4      The best way to travel from Tel Aviv to Jerusa...   \n",
       "...                                                  ...   \n",
       "57472  Sure, lets break it down 1. How has 3 letters....   \n",
       "57473  Here is an implementation of a naive Bayes cla...   \n",
       "57474  Working on weapons technology raises some ethi...   \n",
       "57475  Bromadiolone is a rodenticide which is most of...   \n",
       "57476                                          27 apples   \n",
       "\n",
       "                                      response_b_cleaned  \\\n",
       "0      As an AI, I dont have personal beliefs or opin...   \n",
       "1      A marriage license and a marriage certificate ...   \n",
       "2      Function calling is the process of invoking a ...   \n",
       "3      When building a classifier for a very rare cat...   \n",
       "4      The best way to travel from Tel-Aviv to Jerusa...   \n",
       "...                                                  ...   \n",
       "57472  Here is how that mnemonic represents the digit...   \n",
       "57473  Sure Heres an implementation of a naive Bayes ...   \n",
       "57474  It depends on the context. Weapons can be used...   \n",
       "57475  As an AI language model, I do not promote or c...   \n",
       "57476  If three kids eat three apples in three days, ...   \n",
       "\n",
       "                                           prompt_tokens  ...  \\\n",
       "0      ['is', 'it', 'morally', 'right', 'to', 'try', ...  ...   \n",
       "1      ['what', 'is', 'the', 'difference', 'between',...  ...   \n",
       "2      ['explain', 'function', 'calling', 'how', 'wou...  ...   \n",
       "3      ['how', 'can', 'create', 'test', 'set', 'for',...  ...   \n",
       "4      ['what', 'is', 'the', 'best', 'way', 'to', 'tr...  ...   \n",
       "...                                                  ...  ...   \n",
       "57472  ['simple', 'mnemonic', 'for', 'how', 'wish', '...  ...   \n",
       "57473  ['in', 'python', 'implement', 'naive', 'bayes'...  ...   \n",
       "57474  ['is', 'it', 'unethical', 'to', 'work', 'on', ...  ...   \n",
       "57475  ['if', 'bait', 'contains', 'bromadiolon', 'the...  ...   \n",
       "57476  ['three', 'kids', 'eat', 'three', 'apples', 'i...  ...   \n",
       "\n",
       "      resp_b_avg_sent_len verbosity_diff a_to_prompt_valuable_ratio  \\\n",
       "0                  19.500          298.0                     24.412   \n",
       "1                  17.000          -83.0                     11.000   \n",
       "2                  18.667         -139.0                     14.100   \n",
       "3                  15.056          276.0                     28.789   \n",
       "4                  15.500          107.0                     15.400   \n",
       "...                   ...            ...                        ...   \n",
       "57472               8.100          -12.0                      2.379   \n",
       "57473               4.105          -11.0                      3.537   \n",
       "57474              17.000          234.0                     35.444   \n",
       "57475              16.200          -87.0                      3.571   \n",
       "57476              25.750         -101.0                      0.105   \n",
       "\n",
       "      b_to_prompt_valuable_ratio  self_ref_diff  self_promo_diff  \\\n",
       "0                          6.882             -2               -1   \n",
       "1                         18.545              0                0   \n",
       "2                         28.000             -2                0   \n",
       "3                         14.263              0                0   \n",
       "4                          8.267              1                1   \n",
       "...                          ...            ...              ...   \n",
       "57472                      2.793              0                0   \n",
       "57473                      3.805              0                0   \n",
       "57474                      9.444              0                0   \n",
       "57475                      7.714             -2               -1   \n",
       "57476                      5.421             -1                0   \n",
       "\n",
       "       fp_ratio_diff  prompt_valuable_category  sentiment_score_response_a  \\\n",
       "0             -0.017                   general                      0.9883   \n",
       "1              0.000                        qa                      0.6908   \n",
       "2             -0.004               computation                      0.1280   \n",
       "3              0.000                        qa                      0.9868   \n",
       "4              0.004                        qa                      0.9702   \n",
       "...              ...                       ...                         ...   \n",
       "57472          0.004                        qa                      0.7506   \n",
       "57473          0.001               computation                      0.0772   \n",
       "57474          0.000                   general                     -0.9881   \n",
       "57475         -0.012                        qa                     -0.7430   \n",
       "57476         -0.010                        qa                      0.0000   \n",
       "\n",
       "       sentiment_score_response_b  \n",
       "0                          0.7951  \n",
       "1                          0.9231  \n",
       "2                         -0.1027  \n",
       "3                          0.9792  \n",
       "4                          0.8519  \n",
       "...                           ...  \n",
       "57472                      0.8689  \n",
       "57473                     -0.7506  \n",
       "57474                     -0.7762  \n",
       "57475                     -0.8774  \n",
       "57476                      0.0000  \n",
       "\n",
       "[57240 rows x 26 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_finalclean = pd.read_csv('Finalclean.csv', index_col=0)\n",
    "df_finalclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f138417f-6bd3-4a0d-972b-f68157c2eb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner',\n",
       "       'prompt_valuable', 'response_a_cleaned', 'response_b_cleaned',\n",
       "       'prompt_tokens', 'response_a_tokens', 'response_b_tokens',\n",
       "       'response_a_vector', 'response_b_vector', 'similarity',\n",
       "       'resp_a_avg_sent_len', 'resp_b_avg_sent_len', 'verbosity_diff',\n",
       "       'a_to_prompt_valuable_ratio', 'b_to_prompt_valuable_ratio',\n",
       "       'self_ref_diff', 'self_promo_diff', 'fp_ratio_diff',\n",
       "       'prompt_valuable_category', 'sentiment_score_response_a',\n",
       "       'sentiment_score_response_b'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_finalclean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d261d29b-4c9d-4e13-8138-e32e3ffe0b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = df_finalclean.loc[:,'resp_a_avg_sent_len':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a45e5d2-1151-429b-8b60-c33fb77fc902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_a_avg_sent_len</th>\n",
       "      <th>resp_b_avg_sent_len</th>\n",
       "      <th>verbosity_diff</th>\n",
       "      <th>a_to_prompt_valuable_ratio</th>\n",
       "      <th>b_to_prompt_valuable_ratio</th>\n",
       "      <th>self_ref_diff</th>\n",
       "      <th>self_promo_diff</th>\n",
       "      <th>fp_ratio_diff</th>\n",
       "      <th>prompt_valuable_category</th>\n",
       "      <th>sentiment_score_response_a</th>\n",
       "      <th>sentiment_score_response_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.292</td>\n",
       "      <td>19.500</td>\n",
       "      <td>298.0</td>\n",
       "      <td>24.412</td>\n",
       "      <td>6.882</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>general</td>\n",
       "      <td>0.9883</td>\n",
       "      <td>0.7951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.250</td>\n",
       "      <td>17.000</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>11.000</td>\n",
       "      <td>18.545</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.9231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.143</td>\n",
       "      <td>18.667</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>14.100</td>\n",
       "      <td>28.000</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>computation</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>-0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.862</td>\n",
       "      <td>15.056</td>\n",
       "      <td>276.0</td>\n",
       "      <td>28.789</td>\n",
       "      <td>14.263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.100</td>\n",
       "      <td>15.500</td>\n",
       "      <td>107.0</td>\n",
       "      <td>15.400</td>\n",
       "      <td>8.267</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>0.8519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57472</th>\n",
       "      <td>3.632</td>\n",
       "      <td>8.100</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>2.379</td>\n",
       "      <td>2.793</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>0.8689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57473</th>\n",
       "      <td>5.370</td>\n",
       "      <td>4.105</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>3.537</td>\n",
       "      <td>3.805</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>computation</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>-0.7506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57474</th>\n",
       "      <td>15.950</td>\n",
       "      <td>17.000</td>\n",
       "      <td>234.0</td>\n",
       "      <td>35.444</td>\n",
       "      <td>9.444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>general</td>\n",
       "      <td>-0.9881</td>\n",
       "      <td>-0.7762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57475</th>\n",
       "      <td>18.750</td>\n",
       "      <td>16.200</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>3.571</td>\n",
       "      <td>7.714</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>qa</td>\n",
       "      <td>-0.7430</td>\n",
       "      <td>-0.8774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57476</th>\n",
       "      <td>2.000</td>\n",
       "      <td>25.750</td>\n",
       "      <td>-101.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>5.421</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57240 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       resp_a_avg_sent_len  resp_b_avg_sent_len  verbosity_diff  \\\n",
       "0                   17.292               19.500           298.0   \n",
       "1                   30.250               17.000           -83.0   \n",
       "2                   20.143               18.667          -139.0   \n",
       "3                   18.862               15.056           276.0   \n",
       "4                   23.100               15.500           107.0   \n",
       "...                    ...                  ...             ...   \n",
       "57472                3.632                8.100           -12.0   \n",
       "57473                5.370                4.105           -11.0   \n",
       "57474               15.950               17.000           234.0   \n",
       "57475               18.750               16.200           -87.0   \n",
       "57476                2.000               25.750          -101.0   \n",
       "\n",
       "       a_to_prompt_valuable_ratio  b_to_prompt_valuable_ratio  self_ref_diff  \\\n",
       "0                          24.412                       6.882             -2   \n",
       "1                          11.000                      18.545              0   \n",
       "2                          14.100                      28.000             -2   \n",
       "3                          28.789                      14.263              0   \n",
       "4                          15.400                       8.267              1   \n",
       "...                           ...                         ...            ...   \n",
       "57472                       2.379                       2.793              0   \n",
       "57473                       3.537                       3.805              0   \n",
       "57474                      35.444                       9.444              0   \n",
       "57475                       3.571                       7.714             -2   \n",
       "57476                       0.105                       5.421             -1   \n",
       "\n",
       "       self_promo_diff  fp_ratio_diff prompt_valuable_category  \\\n",
       "0                   -1         -0.017                  general   \n",
       "1                    0          0.000                       qa   \n",
       "2                    0         -0.004              computation   \n",
       "3                    0          0.000                       qa   \n",
       "4                    1          0.004                       qa   \n",
       "...                ...            ...                      ...   \n",
       "57472                0          0.004                       qa   \n",
       "57473                0          0.001              computation   \n",
       "57474                0          0.000                  general   \n",
       "57475               -1         -0.012                       qa   \n",
       "57476                0         -0.010                       qa   \n",
       "\n",
       "       sentiment_score_response_a  sentiment_score_response_b  \n",
       "0                          0.9883                      0.7951  \n",
       "1                          0.6908                      0.9231  \n",
       "2                          0.1280                     -0.1027  \n",
       "3                          0.9868                      0.9792  \n",
       "4                          0.9702                      0.8519  \n",
       "...                           ...                         ...  \n",
       "57472                      0.7506                      0.8689  \n",
       "57473                      0.0772                     -0.7506  \n",
       "57474                     -0.9881                     -0.7762  \n",
       "57475                     -0.7430                     -0.8774  \n",
       "57476                      0.0000                      0.0000  \n",
       "\n",
       "[57240 rows x 11 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9edf1ba-eb6f-4992-aa12-a54b80f0882b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner',\n",
       "       'prompt_valuable', 'response_a_cleaned', 'response_b_cleaned',\n",
       "       'jaccard_sim_resp_a', 'jaccard_sim_resp_b', 'bow_sim_resp_A',\n",
       "       'bow_sim_resp_B', 'num_words_response_a', 'num_words_response_b',\n",
       "       'cosine_sim', 'resp_a_avg_sent_len', 'resp_b_avg_sent_len',\n",
       "       'verbosity_diff', 'a_to_prompt_valuable_ratio',\n",
       "       'b_to_prompt_valuable_ratio', 'self_ref_diff', 'self_promo_diff',\n",
       "       'fp_ratio_diff', 'prompt_valuable_category',\n",
       "       'sentiment_score_response_a', 'sentiment_score_response_b'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = df.join(new_features)\n",
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ba0e226-a894-4412-bde2-7b281643ff2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>prompt_valuable</th>\n",
       "      <th>response_a_cleaned</th>\n",
       "      <th>response_b_cleaned</th>\n",
       "      <th>jaccard_sim_resp_a</th>\n",
       "      <th>...</th>\n",
       "      <th>resp_b_avg_sent_len</th>\n",
       "      <th>verbosity_diff</th>\n",
       "      <th>a_to_prompt_valuable_ratio</th>\n",
       "      <th>b_to_prompt_valuable_ratio</th>\n",
       "      <th>self_ref_diff</th>\n",
       "      <th>self_promo_diff</th>\n",
       "      <th>fp_ratio_diff</th>\n",
       "      <th>prompt_valuable_category</th>\n",
       "      <th>sentiment_score_response_a</th>\n",
       "      <th>sentiment_score_response_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>Is it morally right to try to have a certain p...</td>\n",
       "      <td>The question of whether it is morally right to...</td>\n",
       "      <td>As an AI, I dont have personal beliefs or opin...</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>...</td>\n",
       "      <td>19.500</td>\n",
       "      <td>298.0</td>\n",
       "      <td>24.412</td>\n",
       "      <td>6.882</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>general</td>\n",
       "      <td>0.9883</td>\n",
       "      <td>0.7951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the difference between marriage licens...</td>\n",
       "      <td>A marriage license is a legal document that al...</td>\n",
       "      <td>A marriage license and a marriage certificate ...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>11.000</td>\n",
       "      <td>18.545</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.9231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>explain function calling. how would you call a...</td>\n",
       "      <td>Function calling is the process of invoking or...</td>\n",
       "      <td>Function calling is the process of invoking a ...</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>...</td>\n",
       "      <td>18.667</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>14.100</td>\n",
       "      <td>28.000</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>computation</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>-0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>How can I create a test set for a very rare ca...</td>\n",
       "      <td>Creating a test set for a very rare category c...</td>\n",
       "      <td>When building a classifier for a very rare cat...</td>\n",
       "      <td>0.064327</td>\n",
       "      <td>...</td>\n",
       "      <td>15.056</td>\n",
       "      <td>276.0</td>\n",
       "      <td>28.789</td>\n",
       "      <td>14.263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the best way to travel from Tel-Aviv t...</td>\n",
       "      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n",
       "      <td>The best way to travel from Tel-Aviv to Jerusa...</td>\n",
       "      <td>0.089431</td>\n",
       "      <td>...</td>\n",
       "      <td>15.500</td>\n",
       "      <td>107.0</td>\n",
       "      <td>15.400</td>\n",
       "      <td>8.267</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>0.8519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_a              model_b  \\\n",
       "0  gpt-4-1106-preview           gpt-4-0613   \n",
       "1           koala-13b           gpt-4-0613   \n",
       "2  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4           koala-13b   gpt-3.5-turbo-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  [\"Is it morally right to try to have a certain...   \n",
       "1  [\"What is the difference between marriage lice...   \n",
       "2  [\"explain function calling. how would you call...   \n",
       "3  [\"How can I create a test set for a very rare ...   \n",
       "4  [\"What is the best way to travel from Tel-Aviv...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  [\"The question of whether it is morally right ...   \n",
       "1  [\"A marriage license is a legal document that ...   \n",
       "2  [\"Function calling is the process of invoking ...   \n",
       "3  [\"Creating a test set for a very rare category...   \n",
       "4  [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "\n",
       "                                          response_b  winner  \\\n",
       "0  [\"As an AI, I don't have personal beliefs or o...       1   \n",
       "1  [\"A marriage license and a marriage certificat...       2   \n",
       "2  [\"Function calling is the process of invoking ...       0   \n",
       "3  [\"When building a classifier for a very rare c...       1   \n",
       "4  [\"The best way to travel from Tel-Aviv to Jeru...       2   \n",
       "\n",
       "                                     prompt_valuable  \\\n",
       "0  Is it morally right to try to have a certain p...   \n",
       "1  What is the difference between marriage licens...   \n",
       "2  explain function calling. how would you call a...   \n",
       "3  How can I create a test set for a very rare ca...   \n",
       "4  What is the best way to travel from Tel-Aviv t...   \n",
       "\n",
       "                                  response_a_cleaned  \\\n",
       "0  The question of whether it is morally right to...   \n",
       "1  A marriage license is a legal document that al...   \n",
       "2  Function calling is the process of invoking or...   \n",
       "3  Creating a test set for a very rare category c...   \n",
       "4  The best way to travel from Tel Aviv to Jerusa...   \n",
       "\n",
       "                                  response_b_cleaned  jaccard_sim_resp_a  ...  \\\n",
       "0  As an AI, I dont have personal beliefs or opin...            0.058824  ...   \n",
       "1  A marriage license and a marriage certificate ...            0.090909  ...   \n",
       "2  Function calling is the process of invoking a ...            0.059524  ...   \n",
       "3  When building a classifier for a very rare cat...            0.064327  ...   \n",
       "4  The best way to travel from Tel-Aviv to Jerusa...            0.089431  ...   \n",
       "\n",
       "   resp_b_avg_sent_len  verbosity_diff  a_to_prompt_valuable_ratio  \\\n",
       "0               19.500           298.0                      24.412   \n",
       "1               17.000           -83.0                      11.000   \n",
       "2               18.667          -139.0                      14.100   \n",
       "3               15.056           276.0                      28.789   \n",
       "4               15.500           107.0                      15.400   \n",
       "\n",
       "   b_to_prompt_valuable_ratio  self_ref_diff  self_promo_diff  fp_ratio_diff  \\\n",
       "0                       6.882             -2               -1         -0.017   \n",
       "1                      18.545              0                0          0.000   \n",
       "2                      28.000             -2                0         -0.004   \n",
       "3                      14.263              0                0          0.000   \n",
       "4                       8.267              1                1          0.004   \n",
       "\n",
       "   prompt_valuable_category  sentiment_score_response_a  \\\n",
       "0                   general                      0.9883   \n",
       "1                        qa                      0.6908   \n",
       "2               computation                      0.1280   \n",
       "3                        qa                      0.9868   \n",
       "4                        qa                      0.9702   \n",
       "\n",
       "   sentiment_score_response_b  \n",
       "0                      0.7951  \n",
       "1                      0.9231  \n",
       "2                     -0.1027  \n",
       "3                      0.9792  \n",
       "4                      0.8519  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d6db9ef-1aba-4b22-963b-4327c72a9701",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['prompt_valuable_category'] = df_final['prompt_valuable_category'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca8ac4f0-d94d-42f1-ae1e-ba45c98d2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.get_dummies(df_final, columns=['prompt_valuable_category'], prefix='cat', drop_first=True)\n",
    "df_final['cat_creation'] = df_final['cat_creation'].astype(int)\n",
    "df_final['cat_general'] = df_final['cat_general'].astype(int)\n",
    "df_final['cat_qa'] = df_final['cat_qa'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66b4f68e-2f7e-4502-bb86-035a162efa5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>prompt_valuable</th>\n",
       "      <th>response_a_cleaned</th>\n",
       "      <th>response_b_cleaned</th>\n",
       "      <th>jaccard_sim_resp_a</th>\n",
       "      <th>...</th>\n",
       "      <th>a_to_prompt_valuable_ratio</th>\n",
       "      <th>b_to_prompt_valuable_ratio</th>\n",
       "      <th>self_ref_diff</th>\n",
       "      <th>self_promo_diff</th>\n",
       "      <th>fp_ratio_diff</th>\n",
       "      <th>sentiment_score_response_a</th>\n",
       "      <th>sentiment_score_response_b</th>\n",
       "      <th>cat_creation</th>\n",
       "      <th>cat_general</th>\n",
       "      <th>cat_qa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>Is it morally right to try to have a certain p...</td>\n",
       "      <td>The question of whether it is morally right to...</td>\n",
       "      <td>As an AI, I dont have personal beliefs or opin...</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>...</td>\n",
       "      <td>24.412</td>\n",
       "      <td>6.882</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.9883</td>\n",
       "      <td>0.7951</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the difference between marriage licens...</td>\n",
       "      <td>A marriage license is a legal document that al...</td>\n",
       "      <td>A marriage license and a marriage certificate ...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000</td>\n",
       "      <td>18.545</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>explain function calling. how would you call a...</td>\n",
       "      <td>Function calling is the process of invoking or...</td>\n",
       "      <td>Function calling is the process of invoking a ...</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>...</td>\n",
       "      <td>14.100</td>\n",
       "      <td>28.000</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>How can I create a test set for a very rare ca...</td>\n",
       "      <td>Creating a test set for a very rare category c...</td>\n",
       "      <td>When building a classifier for a very rare cat...</td>\n",
       "      <td>0.064327</td>\n",
       "      <td>...</td>\n",
       "      <td>28.789</td>\n",
       "      <td>14.263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the best way to travel from Tel-Aviv t...</td>\n",
       "      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n",
       "      <td>The best way to travel from Tel-Aviv to Jerusa...</td>\n",
       "      <td>0.089431</td>\n",
       "      <td>...</td>\n",
       "      <td>15.400</td>\n",
       "      <td>8.267</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>0.8519</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57472</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>[\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...</td>\n",
       "      <td>[\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...</td>\n",
       "      <td>[\"Here is how that mnemonic represents the dig...</td>\n",
       "      <td>1</td>\n",
       "      <td>A simple mnemonic for How I wish I could enume...</td>\n",
       "      <td>Sure, lets break it down 1. How has 3 letters....</td>\n",
       "      <td>Here is how that mnemonic represents the digit...</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>...</td>\n",
       "      <td>2.379</td>\n",
       "      <td>2.793</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>0.8689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57473</th>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>[\"In python, implement a naive Bayes with gaus...</td>\n",
       "      <td>[\"Here is an implementation of a naive Bayes c...</td>\n",
       "      <td>[\"Sure! Here's an implementation of a naive Ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>In python, implement a naive Bayes with gaussi...</td>\n",
       "      <td>Here is an implementation of a naive Bayes cla...</td>\n",
       "      <td>Sure Heres an implementation of a naive Bayes ...</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.537</td>\n",
       "      <td>3.805</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>-0.7506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57474</th>\n",
       "      <td>claude-1</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>[\"is it unethical to work on building weapons?...</td>\n",
       "      <td>[\"Working on weapons technology raises some et...</td>\n",
       "      <td>[\"It depends on the context. Weapons can be us...</td>\n",
       "      <td>1</td>\n",
       "      <td>is it unethical to work on building weapons</td>\n",
       "      <td>Working on weapons technology raises some ethi...</td>\n",
       "      <td>It depends on the context. Weapons can be used...</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>...</td>\n",
       "      <td>35.444</td>\n",
       "      <td>9.444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.9881</td>\n",
       "      <td>-0.7762</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57475</th>\n",
       "      <td>palm-2</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>[\"If a bait contains 0,0025% bromadiolon then ...</td>\n",
       "      <td>[\"Bromadiolone is a rodenticide which is most ...</td>\n",
       "      <td>[\"As an AI language model, I do not promote or...</td>\n",
       "      <td>2</td>\n",
       "      <td>If a bait contains 0,0025 bromadiolon then how...</td>\n",
       "      <td>Bromadiolone is a rodenticide which is most of...</td>\n",
       "      <td>As an AI language model, I do not promote or c...</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>...</td>\n",
       "      <td>3.571</td>\n",
       "      <td>7.714</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.7430</td>\n",
       "      <td>-0.8774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57476</th>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[\"three kids eat three apples in three days, h...</td>\n",
       "      <td>[\"27 apples\"]</td>\n",
       "      <td>[\"If three kids eat three apples in three days...</td>\n",
       "      <td>1</td>\n",
       "      <td>three kids eat three apples in three days, how...</td>\n",
       "      <td>27 apples</td>\n",
       "      <td>If three kids eat three apples in three days, ...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105</td>\n",
       "      <td>5.421</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57240 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model_a              model_b  \\\n",
       "0      gpt-4-1106-preview           gpt-4-0613   \n",
       "1               koala-13b           gpt-4-0613   \n",
       "2      gpt-3.5-turbo-0613       mistral-medium   \n",
       "3        llama-2-13b-chat  mistral-7b-instruct   \n",
       "4               koala-13b   gpt-3.5-turbo-0314   \n",
       "...                   ...                  ...   \n",
       "57472          gpt-4-0613             claude-1   \n",
       "57473          claude-2.0     llama-2-13b-chat   \n",
       "57474            claude-1           alpaca-13b   \n",
       "57475              palm-2       tulu-2-dpo-70b   \n",
       "57476  gemini-pro-dev-api   gpt-4-1106-preview   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      [\"Is it morally right to try to have a certain...   \n",
       "1      [\"What is the difference between marriage lice...   \n",
       "2      [\"explain function calling. how would you call...   \n",
       "3      [\"How can I create a test set for a very rare ...   \n",
       "4      [\"What is the best way to travel from Tel-Aviv...   \n",
       "...                                                  ...   \n",
       "57472  [\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...   \n",
       "57473  [\"In python, implement a naive Bayes with gaus...   \n",
       "57474  [\"is it unethical to work on building weapons?...   \n",
       "57475  [\"If a bait contains 0,0025% bromadiolon then ...   \n",
       "57476  [\"three kids eat three apples in three days, h...   \n",
       "\n",
       "                                              response_a  \\\n",
       "0      [\"The question of whether it is morally right ...   \n",
       "1      [\"A marriage license is a legal document that ...   \n",
       "2      [\"Function calling is the process of invoking ...   \n",
       "3      [\"Creating a test set for a very rare category...   \n",
       "4      [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "...                                                  ...   \n",
       "57472  [\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...   \n",
       "57473  [\"Here is an implementation of a naive Bayes c...   \n",
       "57474  [\"Working on weapons technology raises some et...   \n",
       "57475  [\"Bromadiolone is a rodenticide which is most ...   \n",
       "57476                                      [\"27 apples\"]   \n",
       "\n",
       "                                              response_b  winner  \\\n",
       "0      [\"As an AI, I don't have personal beliefs or o...       1   \n",
       "1      [\"A marriage license and a marriage certificat...       2   \n",
       "2      [\"Function calling is the process of invoking ...       0   \n",
       "3      [\"When building a classifier for a very rare c...       1   \n",
       "4      [\"The best way to travel from Tel-Aviv to Jeru...       2   \n",
       "...                                                  ...     ...   \n",
       "57472  [\"Here is how that mnemonic represents the dig...       1   \n",
       "57473  [\"Sure! Here's an implementation of a naive Ba...       1   \n",
       "57474  [\"It depends on the context. Weapons can be us...       1   \n",
       "57475  [\"As an AI language model, I do not promote or...       2   \n",
       "57476  [\"If three kids eat three apples in three days...       1   \n",
       "\n",
       "                                         prompt_valuable  \\\n",
       "0      Is it morally right to try to have a certain p...   \n",
       "1      What is the difference between marriage licens...   \n",
       "2      explain function calling. how would you call a...   \n",
       "3      How can I create a test set for a very rare ca...   \n",
       "4      What is the best way to travel from Tel-Aviv t...   \n",
       "...                                                  ...   \n",
       "57472  A simple mnemonic for How I wish I could enume...   \n",
       "57473  In python, implement a naive Bayes with gaussi...   \n",
       "57474        is it unethical to work on building weapons   \n",
       "57475  If a bait contains 0,0025 bromadiolon then how...   \n",
       "57476  three kids eat three apples in three days, how...   \n",
       "\n",
       "                                      response_a_cleaned  \\\n",
       "0      The question of whether it is morally right to...   \n",
       "1      A marriage license is a legal document that al...   \n",
       "2      Function calling is the process of invoking or...   \n",
       "3      Creating a test set for a very rare category c...   \n",
       "4      The best way to travel from Tel Aviv to Jerusa...   \n",
       "...                                                  ...   \n",
       "57472  Sure, lets break it down 1. How has 3 letters....   \n",
       "57473  Here is an implementation of a naive Bayes cla...   \n",
       "57474  Working on weapons technology raises some ethi...   \n",
       "57475  Bromadiolone is a rodenticide which is most of...   \n",
       "57476                                          27 apples   \n",
       "\n",
       "                                      response_b_cleaned  jaccard_sim_resp_a  \\\n",
       "0      As an AI, I dont have personal beliefs or opin...            0.058824   \n",
       "1      A marriage license and a marriage certificate ...            0.090909   \n",
       "2      Function calling is the process of invoking a ...            0.059524   \n",
       "3      When building a classifier for a very rare cat...            0.064327   \n",
       "4      The best way to travel from Tel-Aviv to Jerusa...            0.089431   \n",
       "...                                                  ...                 ...   \n",
       "57472  Here is how that mnemonic represents the digit...            0.190476   \n",
       "57473  Sure Heres an implementation of a naive Bayes ...            0.152000   \n",
       "57474  It depends on the context. Weapons can be used...            0.033520   \n",
       "57475  As an AI language model, I do not promote or c...            0.060606   \n",
       "57476  If three kids eat three apples in three days, ...            0.083333   \n",
       "\n",
       "       ...  a_to_prompt_valuable_ratio  b_to_prompt_valuable_ratio  \\\n",
       "0      ...                      24.412                       6.882   \n",
       "1      ...                      11.000                      18.545   \n",
       "2      ...                      14.100                      28.000   \n",
       "3      ...                      28.789                      14.263   \n",
       "4      ...                      15.400                       8.267   \n",
       "...    ...                         ...                         ...   \n",
       "57472  ...                       2.379                       2.793   \n",
       "57473  ...                       3.537                       3.805   \n",
       "57474  ...                      35.444                       9.444   \n",
       "57475  ...                       3.571                       7.714   \n",
       "57476  ...                       0.105                       5.421   \n",
       "\n",
       "       self_ref_diff  self_promo_diff  fp_ratio_diff  \\\n",
       "0                 -2               -1         -0.017   \n",
       "1                  0                0          0.000   \n",
       "2                 -2                0         -0.004   \n",
       "3                  0                0          0.000   \n",
       "4                  1                1          0.004   \n",
       "...              ...              ...            ...   \n",
       "57472              0                0          0.004   \n",
       "57473              0                0          0.001   \n",
       "57474              0                0          0.000   \n",
       "57475             -2               -1         -0.012   \n",
       "57476             -1                0         -0.010   \n",
       "\n",
       "       sentiment_score_response_a  sentiment_score_response_b  cat_creation  \\\n",
       "0                          0.9883                      0.7951             0   \n",
       "1                          0.6908                      0.9231             0   \n",
       "2                          0.1280                     -0.1027             0   \n",
       "3                          0.9868                      0.9792             0   \n",
       "4                          0.9702                      0.8519             0   \n",
       "...                           ...                         ...           ...   \n",
       "57472                      0.7506                      0.8689             0   \n",
       "57473                      0.0772                     -0.7506             0   \n",
       "57474                     -0.9881                     -0.7762             0   \n",
       "57475                     -0.7430                     -0.8774             0   \n",
       "57476                      0.0000                      0.0000             0   \n",
       "\n",
       "       cat_general  cat_qa  \n",
       "0                1       0  \n",
       "1                0       1  \n",
       "2                0       0  \n",
       "3                0       1  \n",
       "4                0       1  \n",
       "...            ...     ...  \n",
       "57472            0       1  \n",
       "57473            0       0  \n",
       "57474            1       0  \n",
       "57475            0       1  \n",
       "57476            0       1  \n",
       "\n",
       "[57240 rows x 29 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cde3ca6f-5307-4f37-9299-bdd2c32e48d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Example data\n",
    "X = df_final.loc[:, 'jaccard_sim_resp_a':]\n",
    "y = df_final['winner']  # your labels: values 0, 1, 2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=200,          # More trees = better accuracy, but slower\n",
    "    max_depth=15,              # Prevents overfitting (try tuning this)\n",
    "    min_samples_split=0.01,       # Default, but you can try higher values (e.g., 5)\n",
    "    min_samples_leaf=0.005,        # Increase if you're seeing overfitting\n",
    "    max_features='sqrt',       # Good for classification (sqrt of 10 ≈ 3 features per split)\n",
    "    class_weight='balanced',   # Optional, use if classes are imbalanced\n",
    "    random_state=42,           # For reproducibility\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "219275e1-d475-4380-9ee2-43635837bfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1524 1019  890]\n",
      " [1191 1894  957]\n",
      " [1195 1057 1721]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.4489\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.44      0.42      3433\n",
      "           1       0.48      0.47      0.47      4042\n",
      "           2       0.48      0.43      0.46      3973\n",
      "\n",
      "    accuracy                           0.45     11448\n",
      "   macro avg       0.45      0.45      0.45     11448\n",
      "weighted avg       0.45      0.45      0.45     11448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Visualize Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1, 2], yticklabels=[0, 1, 2])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Accuracy Score\n",
    "acc = accuracy_score(y_test, preds)\n",
    "print(f\"\\nAccuracy: {acc:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(y_test, preds)\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5854e912-ba51-445f-9381-f53596cf97e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Feature  Importance\n",
      "9               verbosity_diff    0.329197\n",
      "4         num_words_response_a    0.103957\n",
      "5         num_words_response_b    0.099250\n",
      "10  a_to_prompt_valuable_ratio    0.077624\n",
      "11  b_to_prompt_valuable_ratio    0.077373\n",
      "6                   cosine_sim    0.064354\n",
      "1           jaccard_sim_resp_b    0.047059\n",
      "0           jaccard_sim_resp_a    0.040858\n",
      "14               fp_ratio_diff    0.030914\n",
      "16  sentiment_score_response_b    0.022060\n",
      "15  sentiment_score_response_a    0.021520\n",
      "3               bow_sim_resp_B    0.020828\n",
      "2               bow_sim_resp_A    0.018736\n",
      "7          resp_a_avg_sent_len    0.017342\n",
      "8          resp_b_avg_sent_len    0.016928\n",
      "12               self_ref_diff    0.006425\n",
      "19                      cat_qa    0.002731\n",
      "18                 cat_general    0.001713\n",
      "13             self_promo_diff    0.001132\n",
      "17                cat_creation    0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importances\n",
    "importances = clf.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame for better readability\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "68266a75-7eae-401b-9384-6ea2c66a3e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test.loc[:, 'jaccard_sim_resp_a':]\n",
    "y = df_test['winner'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f3257393-2ff9-445e-9067-cd232aead38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[0 0 0]\n",
      " [1 1 0]\n",
      " [0 0 1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.6667\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.50      0.67         2\n",
      "           2       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.67      0.50      0.56         3\n",
      "weighted avg       1.00      0.67      0.78         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y, preds)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Visualize Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1, 2], yticklabels=[0, 1, 2])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Accuracy Score\n",
    "acc = accuracy_score(y, preds)\n",
    "print(f\"\\nAccuracy: {acc:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(y, preds)\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03026d2e-0272-4c22-a81c-eab1b3ec5533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
